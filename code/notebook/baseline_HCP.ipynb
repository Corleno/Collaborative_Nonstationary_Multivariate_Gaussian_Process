{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import *\n",
    "TensorType = torch.DoubleTensor\n",
    "from nmgp_dsvi import *\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data = \"HCP\"\n",
    "data_file = \"data.pickle\"\n",
    "if not os.path.exists(\"../../res/{}\".format(data)):\n",
    "    os.mkdir(\"../../res/{}\".format(data))\n",
    "\n",
    "# Upload Data\n",
    "with open(\"../../data/{}/{}\".format(data, data_file), \"rb\") as res:\n",
    "    X_list, Y_list, Xt_list, Yt_list = pickle.load(res)\n",
    "\n",
    "n_dims = len(X_list)\n",
    "\n",
    "# convert data format\n",
    "X_train_list = [x[:, None] for x in X_list]\n",
    "X_test_list = [x[:, None] for x in Xt_list]\n",
    "X_train_vec = np.concatenate(X_train_list)\n",
    "X_test_vec = np.concatenate(X_test_list)\n",
    "Y_train_list = [y[:, None] for y in Y_list]\n",
    "Y_test_list = [y[:, None] for y in Yt_list]\n",
    "Y_train_vec = np.concatenate(Y_train_list)\n",
    "Y_test_vec = np.concatenate(Y_test_list)\n",
    "train_index = np.concatenate([np.ones_like(Y_train_list[i])*i for i in range(n_dims)]).astype(int)\n",
    "test_index = np.concatenate([np.ones_like(Y_test_list[i])*i for i in range(n_dims)]).astype(int)\n",
    "\n",
    "t_max = np.max([np.max(np.concatenate(X_list)), np.max(np.concatenate(Xt_list))])\n",
    "\n",
    "do_plot_raw_data = True\n",
    "\n",
    "if do_plot_raw_data:\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax1.set_title('Output 1')\n",
    "    ax1.plot(X_train_list[0], Y_train_list[0],'kx',mew=1.5,label='Train set')\n",
    "    ax1.plot(X_test_list[0], Y_test_list[0],'rx',mew=1.5,label='Test set')\n",
    "    ax1.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% HCP subset\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Sparse GPR\n",
    "import GPy\n",
    "\n",
    "K = GPy.kern.Exponential(1)\n",
    "m1 = GPy.models.SparseGPRegression(X_train_list[0], Y_train_list[0], kernel=K.copy(), num_inducing=100)\n",
    "m1.optimize(messages=True)\n",
    "test_index = np.concatenate([i*np.ones_like(X_test_list[i]) for i in range(n_dims)]).astype(int)\n",
    "est_Y_test = m1.predict(X_test_list[0])[0]\n",
    "\n",
    "print(m1)\n",
    "\n",
    "rmse_test = np.sqrt(np.mean((est_Y_test - np.vstack(Y_test_list)) ** 2))\n",
    "print(rmse_test)\n",
    "# fig = plt.figure()\n",
    "# ax1 = fig.add_subplot(111)\n",
    "# ax1.set_title('Output 1')\n",
    "# ax1.plot(grids, est_Y_grid,'kx',mew=1.5, label='Prediction set')\n",
    "# ax1.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Sparse Corregionalization Model\n",
    "import GPy\n",
    "\n",
    "K = GPy.kern.Exponential(1)\n",
    "icm = GPy.util.multioutput.ICM(input_dim=1,num_outputs=n_dims,kernel=K)\n",
    "m2 = GPy.models.SparseGPCoregionalizedRegression(X_train_list,Y_train_list,kernel=icm,num_inducing=100)\n",
    "m2['.*Exponential.var'].constrain_fixed(1.) #For this kernel, B.kappa encodes the variance now.\n",
    "print(\"start\")\n",
    "print(m2.log_likelihood())\n",
    "m2.optimize(messages=True)\n",
    "\n",
    "ts = time.time()\n",
    "Xt_vecs = np.vstack([np.hstack([X_test_list[i], np.ones_like(X_test_list[i])*i]) for i in range(n_dims)])\n",
    "noise_dictt = {'output_index':Xt_vecs[:,1].astype(int)}\n",
    "est_Y_test = m2.predict(Xt_vecs, Y_metadata=noise_dictt)[0]\n",
    "\n",
    "print(m2)\n",
    "\n",
    "rmse_test = np.sqrt(np.mean((est_Y_test - np.vstack(Y_test_list)) ** 2))\n",
    "print(rmse_test)\n",
    "print(time.time() - ts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}